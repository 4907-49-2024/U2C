    \subsection{Background \& Terminology}\label{subsec:background-&-terminology}

    \subsection{System Development}

    \label{subsec:system-development}
    % Change to User requirements?
    \subsubsection{User Requirements}\label{subsubsec:user-reqs}

    These User Requirements represent our original set of requirements, with minimal implementation details, and domain knowledge.
    They are elicited from initial discussions with our supervisor,
    and interpretations of the problem statement.
    We did not establish a procedure for explicit lower level requirements after this stage.

    Some limitations of this process is a lack of explicit detail, priorities, or levels of satisfaction for non-functional requirements.
    Instead, we will use later stages of the system development to trace design decisions taken for these requirements.
    We will also touch on priorities and possible improvements when we explain
    which requirements were skipped for our current release in section~\ref{subsubsec:unsat-reqs}.

    The table of requirements contains a list of User Requirements for our system,
    with green states indicating satisfactory completion, and gray indicating unsatisfactory:
    % Requirement table
    \begin{longtable}{|l|p{2.6cm}|l|p{4.5cm}|c|}
        \caption{Set of User Requirements for U2C}
        \label{tab:user-reqs}
        \hline
        \textbf{ID} & \textbf{Requirement} & \textbf{Type}  & \textbf{Description} & \textbf{State}\\
        \hline
        \endhead
        \hline
        % Requirements here
        1 & Input & Functional & U2C shall accept visual system models as input. & \cellcolor{green!30}  \\
        \hline
        2 & C2KA Specifications & Functional & U2C shall interpret given inputs to derive a complete C2KA agent specification. & \cellcolor{green!30}  \\
        \hline
        3 & IIAT Parameters & Functional & U2C shall interpret given inputs to derive the other required IIAT inputs. & \cellcolor{gray!30}  \\
        \hline
        4 & Output & Functional & U2C shall output its computed inputs as text files. & \cellcolor{green!30}  \\
        \hline
        5 & Minimal User Actions & Usability & U2C shall require no additional inputs from the user apart from those required to provide system models. & \cellcolor{green!30}  \\
        \hline
        6 & Modelling Tool Support & Compatibility & U2C shall support models produced by at least one chosen modelling tool (Papyrus, LucidChart, StarUML). & \cellcolor{green!30}  \\
        \hline
        7 & Modelling Language Support & Compatibility & U2C shall support visual models drawn in at least one type of modelling language (ex: UML, SysML, BPMN). & \cellcolor{green!30}  \\
        \hline
        8 & Diagram Type Support & Compatibility & U2C shall support diagrams corresponding to at least one chosen type (ex: state, collaboration, etc.). & \cellcolor{green!30}  \\
        \hline
        9 & Cross Tool Integration & Compatibility & U2C should provide options to integrate directly into tools it depends on (input producer, and output consumers). & \cellcolor{gray!30}  \\
        \hline
        10 & OS Support & Portability & U2C shall run on at least one chosen OS distribution. & \cellcolor{green!30}  \\
        \hline
        11 & Simple System Analysis Speed & Performance & U2C shall produce outputs for a simple system within one minute of execution on a chosen platform specification.
        A simple system is defined as having up to five agents, twenty stimuli, and five behaviors per agent. & \cellcolor{gray!30}  \\
        \hline
        12 & Worst Case Mitigation & Scalability & U2C should scale at a smaller rate than O($n^3$). The expected scaling factors are agents, stimuli, and agent behaviors. & \cellcolor{gray!30}  \\
        \hline
        13 & User Documentation & Maintainability & The U2C code repository shall contain a user manual detailing expected user interactions, and input formats. & \cellcolor{gray!30}  \\
        \hline
        14 & Maintainer Documentation & Maintainability & The U2C code repository shall contain documentation detailing implementation details for maintainers. & \cellcolor{green!30}  \\
        \hline
        15 & Verification Testing & Maintainability & The U2C code repository shall contain automated regression tests providing adequate coverage of the program source code. & \cellcolor{green!30}  \\
        \hline
        16 & Accurate Outputs & Reliability & U2C shall provide deterministic outputs representing accurately what the inputs contain. & \cellcolor{green!30}  \\
        \hline
        17 & No False Positives & Reliability & U2C shall not provide outputs if it cannot find a deterministic interpretation of the given inputs. & \cellcolor{green!30}  \\
        \hline
    \end{longtable}

    \subsubsection{Chosen Input Type}
    The first decision to take concerning inputs was the specific diagram type to support.
    This decision impacts the language, since the diagram type may be specific to one or a small set of languages.
    It also impacts the modelling tool because it needs to support creating that diagram type.
    Most importantly, if the diagram does not have the information we require, there is no purpose in processing it.

    Recall that the information we require is related to creating C2KA agent specifications.
    Our initial diagram choice was \textit{collaboration diagrams}, due to their simplicity. 
    When we learned more about C2KA, we realized they do not model agent behavior very well.
    Collaboration diagrams are more suited to describe a specific scenario on an entire system.
    Instead, we found that having one \textbf{UML State Diagram} per agent is enough to simply capture agent specifications.
    More details on this later when we break down relevant components of state diagrams in section~\ref{subsubsec:input-specification}.

    By choosing UML State Diagrams, we also choose \textbf{UML} as our modelling language.
    SysML could have been a close viable alternative, but we decided to choose a language we were more familiar with.
    This makes it easier to implement properly for us,
    but it is also related to our problem statement aiming to use modelling languages already familiar to system designers to reduce the learning curve.
    Admittedly outside of software system design SysML is more prevalent, and it is feasible to support both, but we had to limit our scope.

    For our modelling tool, we chose \textbf{Papyrus}.
    We established evaluation criteria to evaluate different tools, and compared the most popular ones we found.
    The most important requirement was machine readability.
    We needed to be able to export some representation of the diagram our system could read outside the modelling tool.
    Additionally, it was an advantage if it was free, popular, and had ongoing support.
    We did not want the modelling tool we depended on to become a hurdle to adopt our program,
    ideally we chose a tool which was already in use.
    Other tools we looked at were Lucidchart, draw.io, Creately, Gliffy, UMLLet, PlantUML (all had poor export functions),
    Modelio (felt hard to use), Astah UML (unpopular),
    StarUML and Visual Paradigm (seemed like good alternatives, but we figured out how to use Papyrus first).

    To export diagrams from Papyrus, there is an option to export \textbf{XMI files}.
    They technically have a .uml file extension in papyrus, but they function the same as XMI files from other tools.
    Once a diagram for an agent is finished in papyrus, we can add its XMI file to our program's \textbf{input folder}.
    Once all agents are done, we can execute the program.
    The user does not need to provide additional inputs.
    A full workflow using our program is described in section~\ref{subsec:usage}.

    The table below is a traceability summary mapping our original user requirements to the concepts refining them.
    Refinements can be correlated by the bolded terms above.

    \begin{table}[htbp]
    \centering
    \caption{Input Decision Requirement Traceability}\label{tab:input-table}\\
    \begin{tabularx}{\textwidth}{| l | l | X |}
        \hline
        \textbf{ID} & \textbf{User Requirement} & \textbf{Refinement} \\
        \hline
        1 & Input & Visual Diagrams are given to the system through XMI file exports from supported modelling tool(s). \\ \hline
        5 & Minimal User Actions & The user puts files in an input folder, then executes the program.  \\ \hline
        6 & Modelling Tool Support & The chosen modelling tool is Papyrus. \\ \hline
        7 & Modelling Language Support & The chosen modelling language is UML. \\ \hline
        8 & Diagram Type Support & The chosen input diagram type is UML State Diagrams. \\ \hline
    \end{tabularx}
    \end{table}

    \newpage
    \subsubsection{Input Specifications}\label{subsubsec:input-specification}
    Although we accept UML State diagrams, there are specific elements that our interpreter cares about.
    The primary goal was to make use of essential model elements only, specifically states and transitions,
    to avoid extra modelling requirements.
    Unfortunately, modelling expressiveness was a smaller priority, as such
    other elements may cause unexpected behavior.
    Ideally, they are ignored.
    The next best case is a descriptive error gets raised and crashes the program preventing a faulty output.
    In the worst case, an inaccurate specification may be generated without warning.

    For the safest behavior, we have defined a known set of valid model elements, along with usage guidelines.
    At a high level, it can be summarized with the following class diagram:
    \\
    % TODO: Insert supported state elems figure here

    The first element in our state diagram is a \textbf{state}.
    States describe a discrete behavior where an invariant condition holds.
    They map directly to \textit{Abstract Behaviors} in C2KA\@.
    \textbf{Atomic States} are states which do not contain other states.
    % TODO: (add C2KA base figures after each paragraph?)

    Atomic States always have a \textbf{doActivity} property,
    as they are needed for C2KA \textit{Concrete Behaviors}.
    doActivities need to follow Dijkstra's Guarded Command Language (GCL) notation (see ??). % TODO: ref or appendix? what to ref
    They are used to assign environmental shared variable values,
    with the option to use conditional flows based on the current environment state.
    Due to typesetting constraints, we had to convert the GCL operands listed in table~\ref{tab:gcl-equivalence}.
    \begin{table}[htbp]
          \centering
          \caption{GCL Conversions for Modelling Tools}\label{tab:gcl-equivalence}\\
          \begin{tabular}{| l | l |}
              % Header
              \hline
              \textbf{Original GCL} & \textbf{Modelling Tool} \\
              % Header end
              \hline
              $\land$ & \&\& \\ \hline
              $\square$ & $|$ \\ \hline
              $\lor$ & $||$ \\ \hline
              $\rightarrow$ & $->$ \\ \hline
          \end{tabular}
    \end{table}
    \\

    \textbf{Transitions} are links between states which describe how changes in state occur.
    We use these transitions and their associated behaviors to compute \textit{Next Behavior} and \textit{Next Stimulus} functions.
    For C2KA, we have defined a precise labelling format to follow \{input-stimulus\}/\{output-stimulus\}.
    This follows state diagram convention, but it does not allow for guards,
    and enforces input and output on all transitions.
    \textit{sequential transitions} are special transitions with a single stimulus, their labelling format is: \{in-and-out-stimulus\}.
    This is because sequential states use the output of one state as the input of the next state in the sequence.
    This allows us to uniquely identify sequential compositions by using a single stimulus as the key identifying property.

    \textbf{Sequential States} are super states (state compositions) with a specific composition pattern.
    There are at least two inner states.
    All inner states are linked by \textit{sequential transitions}.
    The sequence has no cycles.
    There is a clear initial state with no incoming transitions.
    There is a clear final state with no outgoing transitions.

    Note: We explicitly decided not cover C2KA \textit{parallel compositions} to simplify modelling and parsing.
    Instead, a modeller should consider making two different agents which communicate
    with each other to model parallel behavior.

    \subsubsection{XMI Parsing}\label{subsubsec:parsing}
    % TODO: look at overlap between this and technical background
    Having chosen our input format, we needed to find a way to parse it to be able to process it.
    Although XMI is supposed to be a standardized format,
    many modelling tools will have slight differences for specific components.
    Therefore, creating a parser which can be extended generally to support many tools can be challenging.

    Thankfully, this is a general problem others have attempted to solve before, and third-party free libraries exist.
    We searched for libraries which supported the most recent UML standards, and we were able to make work.
    The libraries we tested were \textit{SDMetrics OpenCore},
    \textit{eclipse UML2}, \textit{Apache Xerces}, \textit{XMIParser, by cqframework}, \textit{xmiparser, python}.
    We only managed to get the \textbf{SDMetrics} Java library to work within our research period.
    Since it adequately met our needs, we did not extend the research period to find other alternatives.

    The table below traces user requirements to the parsing choices refining them in this section.
    \begin{table}[htbp]
        \centering
        \caption{Parser Requirement Traceability}\label{tab:parse-choice-table}\\
        \begin{tabularx}{\textwidth}{| l | l | X |}
            % Header
            \hline
            \textbf{ID} & \textbf{User Requirement} & \textbf{Refinement} \\
            % Header end
            \hline
            1 & Input & Use SD Metrics OpenCore library to parse XMI file inputs. \\ \hline
        \end{tabularx}
    \end{table}

    \newpage
    \subsubsection{Target Deployment}
    One of our user requirements requires us to target an Operating System.
    Just like the choice of modelling tool, we want to avoid the OS target to be a barrier to our tool.
    We also want to avoid incurring costs attempting to port our tool across multiple Operating Systems.
    \textbf{Java} is a great language which allows us to run the same program on any OS due to the Java Virtual Machine.

    We considered \textit{C}, but it is not as simple to make platform independent.
    \textit{Python} was also a valid alternative because it is also platform independent.
    The deciding factor was the availability of third party libraries.
    As mentioned in section~\ref{subsubsec:parsing} The SD Metrics library we use for XMI parsing in our system was implemented in Java.
    We were not able to make any alternatives work in Python.
    With no particular need for other languages, we decided to keep it simple by only using Java in our program.

    The table below traces user requirements to the deployment choices refining them in this section.
    \begin{table}[htbp]
        \centering
        \caption{Deployment Requirement Traceability}\label{tab:os-choice-table}\\
        \begin{tabularx}{\textwidth}{| l | l | X |}
            % Header
            \hline
            \textbf{ID} & \textbf{User Requirement} & \textbf{Refinement} \\
            % Header end
            \hline
            10 & OS Support & Use java for platform independence. \\ \hline
        \end{tabularx}
    \end{table}

    \newpage
    \subsubsection{Architecture Choice}
    Choosing how to structure our code depends strongly on our functional requirements,
    but quality attributes can play a role as well.
    The most relevant quality attributes for the architecture for are scalability and performance.
    The other requirements are addressed at different steps of the design process.

    To begin with, we can think about what our program does not need, like user interaction during execution.
    This already gets rid of the need for user interaction focused patterns like \textit{Model-View-Controller} and its variants.
    We also have no need for a server or decentralized processing unless we failed to meet our performance goal on one computer.
    We did not expect performance to be an issue big enough to require decentralized processing.
    Thus, we can eliminate any server patterns, including \textit{microservice} and \textit{service oriented} architectures.

    The initial architecture we chose was the \textit{Layer Pattern}, because it fits quite well with the flow of our program.
    We are provided an input, and do a series of unidirectional transformations on it to produce an output at the end.
    We believed these transformations made sense as different layers of our program.
    Layers could pass their outputs through defined input interfaces of the next layer.
    This is great for separation of concerns and maintainability.
    It is also a great way to reason about the system allowing us to convert our understanding of C2KA transformation to code easily.

    That said, we then realized we were starting to describe a \textbf{Pipe and Filter} architecture.
    Instead of layers to transform data, we use filters.
    We use pipes as our interface to communicate between them.
    We still have great separation of concerns, and the same straightforward reasoning for implementation.
%    In fact, we can still informally categorize filters into layers for organization as we will see in section~\ref{subsubsec:arch-desc}
    The advantage we gain from this pivot is the ability to increase parallelization of processing compared to the layered architecture.
    This allows us to directly improve our \textbf{performance} and \textbf{scalability} by reducing the impact of increased data set sizes.

    The table below traces user requirements to the architecture choices refining them in this section.

    \begin{table}[htbp]
        \centering
        \caption{Architecture Choice Requirement Traceability}\label{tab:arch-choice-table}\\
        \begin{tabularx}{\textwidth}{| l | l | X |}
            % Header
            \hline
            \textbf{ID} & \textbf{User Requirement} & \textbf{Refinement} \\
            % Header end
            \hline
            11 & Simple System Analysis Speed & Use parallelization enabled by Pipe and Filter to improve performance. \\ \hline
            12 & Worst Case Mitigation & Use parallelization enabled by Pipe and Filter to reduce scaling costs.  \\ \hline
        \end{tabularx}
    \end{table}

    \newpage
    \subsubsection{Architecture Description}\label{subsubsec:arch-desc}
    To describe the concrete implementation of our design,
    we will break down the responsibilities of our filters, and the pipes in our system through a visual representation.
    In these representations, the filters are the named rounded rectangles.
    The directional associations show data flow between filters.
    Annotations on the data flows specify what data is contained in the pipe.
    We also have forks, which are flows going into a black vertical bar and splitting, showing when data is re-used in parallel.
    Joins are the opposite operation, collecting data from independent parallel operations back into one centralized point.
    Finally, we have the cloud to indicate a simplification in the diagram.
    It explains which details were omitted from the model to make it easier to understand.

    The first part of our architecture model focuses on converting our expected input to a StateDiagram internally.
    % TODO: Model P1 here
    When the program starts execution, it reads all the model files at once from a known input address.
    It forks once for each model to process them all in parallel.
    The first transformation step is to parse the \textit{XMI file} with our \textbf{XMI Parser}.
    The parser uses the SDMetrics library to extract generic UML \textit{ModelElements}.

    These elements need to be passed to our \textbf{State Diagram Linker}
    to build an internal representation of a \textit{state diagram} for our program.
    Specifically, we strongly type model elements according to our internally defined types (states, and transitions).
    Super states can be thought of as tree roots, and a state diagram can also be represented as a super state.
    This allows us to recursively interpret our diagram just like a tree during the following \textbf{diagram interpretation} stage.

    The second part of our model completes the process, going from internal StateDiagram to the desired output.
    % TODO Model P2
    From our \textit{state diagram}, we can perform different analyses in parallel to find parts of the C2KA specification.
    The \textbf{abstract behavior interpreter} looks at super states to find sequential compositions,
    and atomic state names to build a C2KA \textit{abstract behavior specification}.
    States which are not sequentially linked are composed by choice.

    The \textbf{concrete behavior interpreter} simply collects all the atomic behaviors and their doActivities.
    The doActivities should already be formatted as the concrete behavior according to our input specification (section~\ref{subsubsec:input-specification}).
    The C2KA \textit{concrete behavior specification} produced is just a formatted collection of the doActivities of the agent.

    The \textbf{next behavior interpreter} checks transitions to find next behavior mappings.
    A mapping is an initial behavior, an input stimulus, and the resulting behavior of the transition.
    The \textit{next behavior specification} is the set of all next behavior mappings found for that agent.

    The \textbf{next stimulus interpreter} is essentially the same as next behavior,
    but instead of the resulting behavior, we check the output stimulus on the transition.
    The \textit{next stimulus specification} is the set of all next stimulus mappings found for that agent.

    Once all the interpretation is complete, it gets joined into a complete \textit{C2KA Specification}.
    We then need to wait at a barrier for all other models to complete analysis before writing our final \textit{output} to a file.

    The reason for the barrier is due to a limitation inherent in C2KA of the next stimulus, and next behavior functions.
    They need to be complete functions,
    meaning behaviors in an agent need to have defined neutral mappings for all stimuli in the system.
    Neutral mappings being outcomes where nothing changes, a neutral stimulus is sent or the behavior remains the same.
    However, since the view of our system is fragmented across our input set,
    we cannot identify all stimuli in the system until we analyze all agent inputs to get a complete view of our system.


    The table below traces user requirements to the architecture implementations refining them in this section.
    \begin{table}[htbp]
        \centering
        \caption{Architecture Description Requirement Traceability}\label{tab:arch-description-table}\\
        \begin{tabularx}{\textwidth}{| l | l | X |}
            % Header
            \hline
            \textbf{ID} & \textbf{User Requirement} & \textbf{Refinement} \\
            % Header end
            \hline
            1 & Input & XMI Parser, and State Diagram Linker used to convert input to a diagram format we can interpret. \\ \hline
            2 & C2KA Specifications & Interpreter filters are used to convert a diagram to partial C2KA specifications.
            They are then combined into a full C2KA specification. \\ \hline
            4 & Output & The complete C2KA Specification to output conversion allows us to extract agent text files as output.  \\ \hline
        \end{tabularx}
    \end{table}

    \newpage
    \subsubsection{Project Management}\label{subsubsec:proj-mngmnt}
    After user requirements, we described our design choices to cover them.
    From design, we needed to create tasks to trace the design to specific code implementation.
    To do so, we used \textbf{GitHub Issues} to build a list of upcoming tasks for the project.
    This allowed us to assign them when resources were available, and communicate task dependencies easily.
    Work done by individuals can be tracked through issues,
    preventing multiple people from working on a task simultaneously unaware.
    The transition from weekly meetings to asynchronous communication through issues improved our efficiency immensely.
    % TODO sample issue list

    We also customized issue tags to categorize issues
    according to our major development concerns, as seen in our repository:
    % TODO: Insert issue types
    \textit{Enhancements} and \textit{bugs} both relate to implementing our design,
    but bugs are errors we found after merging the initial enhancement implementation.
    \textit{Verification \& Validation} (V\&V) Tasks related to verifying our code, and validating it.
    Usually through creating new tests, but it can also include creating tools for testing,
    or establishing and documenting V\&V requirements or strategies.

    \textit{Questions} are typically related to clarifications on requirements,
    or designs which require research or input from our supervisor.
    Once a question is answered, we typically reply directly in the question issue and close it.
    Usually, questions have a purpose and can create new issues or unblock existing ones as well.
    \textit{Documentation} Tasks related to documenting our project, for any audience.
    This includes documentation like this report, function descriptions in code, and a user manual.

    \textit{Out of scope} Marks tasks which we identified as out of scope for our current release.
    These can include requirements we create to explicitly exclude from the start,
    or existing issues we drop later due to time constraints.
    In the case where an issue is deemed irrelevant, we do not mark it out of scope.
    Instead, we close the issue with a comment for rationale and stop tracking it.
    On release, we reset the scope constraints by removing this label on all issues.
    After an evaluation of the goals of the next release,
    maintainers can decide which issues should stay within the scope of the next release.

    We did not develop a great way to automatically trace issues to design,
    and we have too many issues to go through them all (over 60 closed issues currently).
    Unfortunately, this means we cannot rely on design to code traceability.
    Instead, we rely only on testing for validation.
    We can, however, demonstrate how we could attempt to manually show traceability through a specific issue.
    %TODO add specific issue, explain

    \newpage
    \subsubsection{Testing Strategy}\label{subsubsec:tests-strat}
    Although we never defined a formal test selection criteria,
    we defined informal guidelines to define how to verify our code.

    For our simplest code unit, \textit{pipes}, we can \textbf{unit test} it.
    After construction, we verify public attributes are as expected.

    For \textit{filters}, we did \textbf{integration tests} to more closely simulate a real program environment.
    For these tests, we called all the filters up to and including the filter under test then evaluated the output.
    This allowed us to do iterative development when we developed new filters,
    ensuring new filter implementations were not breaking any previously implemented filters.
    The following diagram shows how an integration test would like when testing the State Diagram Linker.
    % TODO Make a diagram to show a test on XMI parser

    For integration test inputs, we defined a group of elementary C2KA representations which implement
    all the elements specified as part of our input specification.
    The diagrams used are the same diagrams included in the input specification section~\ref{subsubsec:input-specification}.

    For the complete \textit{C2KASpecification} we did end to end \textbf{system tests}, with a \textbf{custom diff tool}.
    To do this, we needed a system with known C2KA outputs.
    We got analyzed systems from our supervisor, which we treated as the source of truth.
    Then, we also needed to model diagrams representing those specifications.
    Finally, we create a test with the diagrams as inputs, the analyzed system as expected outputs,
    and compare them with our diff tool.

    The reason we needed a custom diff tool is due to the inevitable differences between manual C2KA analysis,
    and our automated analysis.
    There may be some whitespace differences or a different ordering of lines
    which are both semantically irrelevant to the specification.
    This is why our diff tool checks for an exact match for lines in a specification type,
    regardless of their location within the block or any whitespace.
    This means that if our actual produced output is missing a line, the diff raises an error,
    but it also raises one if our output has an extra line which is not in the expected output.

    % TODO show output differences

    The table below traces user requirements to our testing strategy concepts refining them in this section.
    \begin{table}[htbp]
        \centering
        \caption{Testing Strategy Requirement Traceability}\label{tab:test-strat-table}\\
        \begin{tabularx}{\textwidth}{| l | l | X |}
            % Header
            \hline
            \textbf{ID} & \textbf{User Requirement} & \textbf{Refinement} \\
            % Header end
            \hline
            15 & Verification Testing & Unit tests, Integration tests provided confidence that our code was continuously functional as we progressed. \\ \hline
            16 & Accurate Outputs & The system tests and diff tool were part of our validation activities to verify output accuracy. \\ \hline
            17 & No False Positives & The system tests should show failures if an output could not be completed, otherwise the diff tool should raise an error. \\ \hline
        \end{tabularx}
    \end{table}
    \newpage
    \subsubsection{Validation Results}\label{subsubsec:test-validation}
    % TODO: Complete validation tests before doing this section

    The table below traces user requirements to our testing results refining them in this section.
    \begin{table}[htbp]
        \centering
        \caption{Validation Requirement Traceability}\label{tab:test-res-table}\\
        \begin{tabularx}{\textwidth}{| l | l | X |}
            % Header
            \hline
            \textbf{ID} & \textbf{User Requirement} & \textbf{Refinement} \\
            % Header end
            \hline
            1 & Input & Functional part of the end to end testing. \\ \hline
            2 & C2KA Specification & Functional part of the end to end testing.\\ \hline
            4 & Output & Functional part of the end to end testing.\\ \hline
            16 & Accurate Outputs & User . \\ \hline %TODO, fill
            17 & No False Positives & . \\ \hline %TODO, fill
        \end{tabularx}
    \end{table}

    \newpage
    \subsubsection{Unsatisfied Requirements} \label{subsubsec:unsat-reqs}
    As we progressed in the project, some lower priority requirements had to be cut to reduce the scope.

    For functional requirements, this meant the \textbf{IIAT Parameters}.
    Although these are nice to have, they may have required support for an additional diagram type for small benefits.
    The core goal of our program was producing the C2KA Specification transformation.

    For non-functional requirements, we completely dropped \textbf{cross tool integration}.
    It seemed complex, yet not essential to prove one version of our program was functional.
    We also cannot claim \textbf{performance} nor \textbf{scalability} of our program due to lack of testing or proofs.
    In theory, these properties should hold with our current design, but we did not take the time to prove it.
    % TODO: Fix this req and move it later, hopefully
    We did not complete \textbf{User Documentation}, instead focusing on building a comprehensive report.
    The user manual should have been the essential sections of the report a user should be aware of,
    formatted in a way which makes it easy to learn about and use our project.

    We also completed some non-functional requirements but in a way that could be improved.
    Our parser allows for multiple \textbf{modelling tool support}, but it still needs to be tested.
    Similarly, we could have potentially supported multiple \textbf{modelling languages} with little extra effort.
    The same may apply to \textbf{diagram types}.
    All of this requires additional tests, and may lead to small tweaks increasing our scope beyond what we could handle.

    \textbf{Maintainer documentation} is good, but it is not systematic.
    There is no automatic way to detect missing documentation to ensure full functional coverage.
    It may also have been good to have a maintainer manual alongside the user manual.
    It could explain design decisions and the program architecture at a lower level than the report for overarching context.
    For now, this report serves adequately for a system specification.

    Our custom diff tool was also not systematically tested.
    This means the reports we rely on for accuracy validation may be inaccurate themselves due to an unknown fault in the diff tool.
    If we had more time, getting better assurance of our diff tool itself would increase our assurance in the program's overall
    \textbf{Reliability}.

    In summary, OS Support and the main functions are the only requirements we have fully covered (green).
    All other requirements are either adequately covered (also green), or not covered (gray),
    as seen in our user requirement table, table~\ref{tab:user-reqs}.


    \subsection{Usage}\label{subsec:usage}
    \subsubsection{Demonstration Scope}
    To use our tool, we will show the full process from how to generate the inputs,
    up to how to provide to our target model checker (IIAT), and the output generated.
    We will assume the reader is familiar with the input specification from section~\ref{subsubsec:input-specification},
    and how to create their desired state diagram following the specification.
    Therefore, we will start by showing how to export an existing state diagram in Papyrus.

    The demonstration will be using inputs generated to simulate the system from % TODO: inlcude appendix or reference?

    % TODO: make sure to name our tool somewhere
    \subsubsection{Exporting Inputs from Papyrus}
    The first step in providing inputs is to export them from Papyrus.
    The following figures will demonstrate the steps required to do so:
    % TODO describe figures, export 1-3

    \subsubsection{Executing U2C}
    To use our program, the first step is to download the 1.0 zip release from GitHub.
    Then, extract the zip as is to a folder.
    Double-click the jar file to execute it (Java 16+ required).
    Open the Output folder, there should be four output files corresponding to the sample input.

    If the output does not get generated, the program did not succeed.
    This is most likely due to an improper java installation.
    Attempt to run the Jar file in the console, for example on Windows the command is:
    \begin{verbatim}
        java -jar U2C.jar
    \end{verbatim}
    This should display some error message which is hopefully helpful enough to troubleshoot.
    Otherwise, raise a bug on GitHub with steps to reproduce it.
    Optionally, contact an individual currently maintaining the tool for help.

    If you had no issues, clean the output and input folders.
    Then, add your sample diagram inputs to the Input folder.
    Execute the program, then collect the output files generated, they will be needed later.

    \subsubsection{Providing Outputs to Model Checker}
    % TODO: run IIAT, issue #139